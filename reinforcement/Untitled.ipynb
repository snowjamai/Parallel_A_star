{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9a4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c91f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"transition 저장\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590190b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Linear 입력의 연결 숫자는 conv2d 계층의 출력과 입력 이미지의 크기에\n",
    "        # 따라 결정되기 때문에 따로 계산을 해야합니다.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # 최적화 중에 다음 행동을 결정하기 위해서 하나의 요소 또는 배치를 이용해 호촐됩니다.\n",
    "    # ([[left0exp,right0exp]...]) 를 반환합니다.\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a21c26e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snowjam1994\\.conda\\envs\\torch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # gym이 요청한 화면은 400x600x3 이지만, 가끔 800x1200x3 처럼 큰 경우가 있습니다.\n",
    "    # 이것을 Torch order (CHW)로 변환한다.\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # 카트는 아래쪽에 있으므로 화면의 상단과 하단을 제거하십시오.\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # 카트를 중심으로 정사각형 이미지가 되도록 가장자리를 제거하십시오.\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # float 으로 변환하고,  rescale 하고, torch tensor 로 변환하십시오.\n",
    "    # (이것은 복사를 필요로하지 않습니다)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # 크기를 수정하고 배치 차원(BCHW)을 추가하십시오.\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b1edbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# AI gym에서 반환된 형태를 기반으로 계층을 초기화 하도록 화면의 크기를\n",
    "# 가져옵니다. 이 시점에 일반적으로 3x40x90 에 가깝습니다.\n",
    "# 이 크기는 get_screen()에서 고정, 축소된 렌더 버퍼의 결과입니다.\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max (1)은 각 행의 가장 큰 열 값을 반환합니다.\n",
    "            # 최대 결과의 두번째 열은 최대 요소의 주소값이므로,\n",
    "            # 기대 보상이 더 큰 행동을 선택할 수 있습니다.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # 도표가 업데이트되도록 잠시 멈춤\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7ef445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). 이것은 batch-array의 Transitions을 Transition의 batch-arrays로\n",
    "    # 전환합니다.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # 최종이 아닌 상태의 마스크를 계산하고 배치 요소를 연결합니다\n",
    "    # (최종 상태는 시뮬레이션이 종료 된 이후의 상태)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Q(s_t, a) 계산 - 모델이 Q(s_t)를 계산하고, 취한 행동의 열을 선택합니다.\n",
    "    # 이들은 policy_net에 따라 각 배치 상태에 대해 선택된 행동입니다.\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # 모든 다음 상태를 위한 V(s_{t+1}) 계산\n",
    "    # non_final_next_states의 행동들에 대한 기대값은 \"이전\" target_net을 기반으로 계산됩니다.\n",
    "    # max(1)[0]으로 최고의 보상을 선택하십시오.\n",
    "    # 이것은 마스크를 기반으로 병합되어 기대 상태 값을 갖거나 상태가 최종인 경우 0을 갖습니다.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # 기대 Q 값 계산\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Huber 손실 계산\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # 모델 최적화\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff621698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    # 환경과 상태 초기화\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # 행동 선택과 수행\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # 새로운 상태 관찰\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # 메모리에 변이 저장\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "\n",
    "        # 최적화 한단계 수행(목표 네트워크에서)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    #목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "894eef21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n"
     ]
    }
   ],
   "source": [
    "a = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34e57313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfd073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
